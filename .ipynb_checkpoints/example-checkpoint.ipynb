{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Log Analysis Examples\n",
      "\n",
      "This notebook contains many useful examples of analysis that can be done on a log file once it has been parsed.  This includes graphing\n",
      "and histogramming garbage collections, compactions, flushes, and exception frequency, as well as querying version and environmental information.\n",
      "\n",
      "Refer to [Diving into Open Data with IPython Notebook & Pandas](http://nbviewer.ipython.org/github/jvns/talks/blob/master/pyconca2013/pistes-cyclables.ipynb) for a quick overview of using IPython and pandas together.  More information can be found on the [IPython](http://ipython.org/) and [pandas](http://pandas.pydata.org/) web pages.\n",
      "\n",
      "These are just some of the things you could do. IPython makes exploratory computing easy, so don't hesitate to try new things!\n",
      "\n",
      "To run a block, click on the code and press `Ctrl`+`Enter`.  You must do this for each individual block in order to refresh it after loading a new log.\n",
      "\n",
      "**Important!** The first two cells must be run before you can do any of the examples below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Initialization\n",
      "\n",
      "This block imports all of the libraries and does any configuration necessary.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "pylab.rcParams['figure.figsize'] = 18, 12\n",
      "\n",
      "import pandas as pd\n",
      "import pprint\n",
      "import cassandra"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Log Parsing\n",
      "\n",
      "This parses the log file and loads it into memory in a JSON-like data structure. There are 3 example log files included, so try them all. You can also use your own log file by passing its full path to the SystemLog constructor. Note that not every example will work with every log. It depends on what's in the log."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logfiles = ['system0.log', 'system1.log', 'system2.log']\n",
      "\n",
      "#0=Good general example\n",
      "#1=Good compaction example\n",
      "#2=Good GC Example\n",
      "\n",
      "reload(cassandra)\n",
      "log = cassandra.SystemLog(logfiles[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Solr Indexing & Bananas\n",
      "\n",
      "This will index the events from the currently loaded log into the Solr included. Once indexed, the log entries can be searched via Solr and browsed in Banana, a port of Kibana to Solr.\n",
      "\n",
      "Setting up:\n",
      "\n",
      "1. Check out Banana from [Github](https://github.com/LucidWorks/banana)\n",
      "1. Create a symlink to the Banana repository called $DSE_HOME/resources/solr/web/banana\n",
      "1. Start DSE in Solr mode\n",
      "1. Run the `add-schema.sh` script to create the schema in DSE.\n",
      "1. Load a log (above), then run the solr_index command below to index it\n",
      "1. Go to http://localhost:8983/banana/src\n",
      "1. An error stating that no index was found will appear. Dismiss it.\n",
      "1. Load the dashboard by clicking on the folder icon at the top and then choosing the banana_dashboard.json file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "./add-schema.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Posting solrconfig.xml to http://jblangston:8983/solr/resource/logparse.systemlog/solrconfig.xml...\n",
        "SUCCESS\n",
        "Posted solrconfig.xml to http://jblangston:8983/solr/resource/logparse.systemlog/solrconfig.xml\n",
        "Posting schema.xml to http://jblangston:8983/solr/resource/logparse.systemlog/schema.xml...\n",
        "SUCCESS\n",
        "Posted schema.xml to http://jblangston:8983/solr/resource/logparse.systemlog/schema.xml\n",
        "Creating index...\n",
        "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<response>\n",
        "<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">2060</int></lst>\n",
        "</response>\n",
        "Created index.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "systemlog.cql:2:Bad Request: Cannot drop non existing keyspace 'logparse'.\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log.solr_index('http://localhost:8983/solr/logparse.systemlog/update')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Environment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log.sessions[1]['environment']['jvm']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame.from_records(log.sessions[1]['versions'], columns=['component','version'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Garbage Collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc = pd.DataFrame.from_records(log.sessions[0]['garbage_collections'], \n",
      "                               columns=['date', 'collections', 'duration'], index='date')\n",
      "#day=gc['20131012']\n",
      "hourly = gc.resample('H', how='sum')\n",
      "hourly.plot(y='duration', logy=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc['duration'].hist(bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame.from_records(log.sessions[0]['heap_warnings'], index='date')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Compactions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compactions = pd.DataFrame.from_records(log.sessions[0]['compactions'],index='begin_date')\n",
      "compactions.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compactions = compactions.dropna()\n",
      "compactions['rate'].resample('H', how='count').plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compactions['rate'].hist(bins=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Flushes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flushes = pd.DataFrame.from_records(log.sessions[0]['flushes'], index='begin_date')\n",
      "flushes['serialized_bytes'].resample('H', how='count').plot()\n",
      "#flushes['queue_duration'] = flushes['begin_date'] - flushes['enqueue_date']\n",
      "#flushes['flush_duration'] = flushes['end_date'] - flushes['begin_date']\n",
      "#flushes.sort('flush_duration')\n",
      "#flushes.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Errors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = pd.DataFrame.from_records(log.sessions[0]['errors'], index='date')\n",
      "errors['exception'].value_counts().plot(kind='barh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Repairs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = []\n",
      "for session in log.sessions[6]['repair_sessions']:\n",
      "    tmp.extend(session.get('inconsistent_endpoints', []))\n",
      "inconsistent = pd.DataFrame.from_records(tmp, index='date')\n",
      "inconsistent.sort(columns=['session_id', 'column_family', 'node1', 'node2']).tail(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = []\n",
      "for session in log.sessions[6]['repair_sessions']:\n",
      "    tmp.extend(session.get('merkle_requests', []))\n",
      "merkle_requests = pd.DataFrame.from_records(tmp, index='request_date')\n",
      "merkle_requests.tail(60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "streaming_sessions = pd.DataFrame.from_records(log.sessions[-1]['streaming_sessions'])\n",
      "streaming_sessions.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sstables_sent = pd.DataFrame.from_records(log.sessions[6]['sstables_sent'], index='date')\n",
      "sstables_sent.tail(60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Status Logger"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thread_pool = pd.DataFrame.from_records(log.sessions[0]['status'][10]['thread_pool'],index='pool_name')\n",
      "thread_pool"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "caches = pd.DataFrame.from_records(log.sessions[0]['status'][2]['caches'],index='type')\n",
      "caches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memtables = pd.DataFrame.from_records(log.sessions[0]['status'][2]['memtables'], columns=['keyspace','column_family','ops','data'])\n",
      "memtables.tail(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unrecognized Messages\n",
      "\n",
      "The log parser isn't complete and probably will always be a work in progress. The goal is to parse the most useful messages first.  This report shows the number of unrecognized messages for each category/source file.  Generally when writing a new parser, I choose one of the categories at the top of the list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unknown = pd.DataFrame.from_records(log.unknown_messages, index='date')\n",
      "unknown[unknown.level == 'INFO'].source_file.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}